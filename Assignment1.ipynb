{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "def readGz(f):\n",
    "    for l in gzip.open(f):\n",
    "        yield eval(l)\n",
    "\n",
    "### Rating baseline: compute averages for each user, or return the global average if we've never seen the user before\n",
    "\n",
    "allRatings = []\n",
    "userRatings = defaultdict(list)\n",
    "for l in readGz(\"train.json.gz\"):\n",
    "    user,business = l['userID'],l['businessID']\n",
    "    allRatings.append(l['rating'])\n",
    "    userRatings[user].append(l['rating'])\n",
    "\n",
    "globalAverage = sum(allRatings) / len(allRatings)\n",
    "userAverage = {}\n",
    "for u in userRatings:\n",
    "    userAverage[u] = sum(userRatings[u]) / len(userRatings[u])\n",
    "\n",
    "predictions = open(\"predictions_Rating.txt\", 'w')\n",
    "for l in open(\"pairs_Rating.txt\"):\n",
    "    if l.startswith(\"userID\"):\n",
    "        #header\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u,i = l.strip().split('-')\n",
    "    if u in userAverage:\n",
    "        predictions.write(u + '-' + i + ',' + str(userAverage[u]) + '\\n')\n",
    "    else:\n",
    "        predictions.write(u + '-' + i + ',' + str(globalAverage) + '\\n')\n",
    "\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Would-visit baseline: just rank which businesses are popular and which are not, and return '1' if a business is among the top-ranked\n",
    "businessCount = defaultdict(int)\n",
    "totalPurchases = 0\n",
    "\n",
    "for l in readGz(\"train.json.gz\"):\n",
    "    user,business = l['userID'],l['businessID']\n",
    "    businessCount[business] += 1\n",
    "    totalPurchases += 1\n",
    "\n",
    "mostPopular = [(businessCount[x], x) for x in businessCount]\n",
    "mostPopular.sort()\n",
    "mostPopular.reverse()\n",
    "\n",
    "return1 = set()\n",
    "count = 0\n",
    "for ic, i in mostPopular:\n",
    "    count += ic\n",
    "    return1.add(i)\n",
    "    if count > totalPurchases/2: break\n",
    "\n",
    "predictions = open(\"predictions_Visit.txt\", 'w')\n",
    "for l in open(\"pairs_Visit.txt\"):\n",
    "    if l.startswith(\"userID\"):\n",
    "    #header\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u,i = l.strip().split('-')\n",
    "    if i in return1:\n",
    "        predictions.write(u + '-' + i + \",1\\n\")\n",
    "    else:\n",
    "        predictions.write(u + '-' + i + \",0\\n\")\n",
    "\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Category prediction baseline: Just consider some of the most common words from each category\n",
    "\n",
    "catDict = {\n",
    "  \"American Restaurant\": 0,\n",
    "  \"Bar\": 1,\n",
    "  \"Asian Restaurant\": 2,\n",
    "  \"European Restaurant\": 3,\n",
    "  \"Italian Restaurant\": 4,\n",
    "  \"Fast Food Restaurant\": 5,\n",
    "  \"Mexican Restaurant\": 6,\n",
    "  \"Seafood Restaurant\": 7,\n",
    "  \"Coffee Shop\": 8,\n",
    "  \"Sandwich Shop\": 9\n",
    "}\n",
    "\n",
    "predictions = open(\"predictions_Category.txt\", 'w')\n",
    "predictions.write(\"userID-reviewHash,category\\n\")\n",
    "for l in readGz(\"test_Category.json.gz\"):\n",
    "    cat = catDict['American Restaurant'] # If there's no evidence, just choose the most common category in the dataset\n",
    "    words = l['reviewText'].lower()\n",
    "    if 'america' in words:\n",
    "        cat = catDict['American Restaurant']\n",
    "    if 'bar' in words or 'beer' in words:\n",
    "        cat = catDict['Bar']\n",
    "    if 'asia' in words:\n",
    "        cat = catDict['Asian Restaurant']\n",
    "    if 'europe' in words:\n",
    "        cat = catDict['European Restaurant']\n",
    "    if 'italian' in words:\n",
    "        cat = catDict['Italian Restaurant']\n",
    "    if 'fast' in words:\n",
    "        cat = catDict['Fast Food Restaurant']\n",
    "    if 'mexic' in words:\n",
    "        cat = catDict['Mexican Restaurant']\n",
    "    if 'coffee' in words:\n",
    "        cat = catDict['Coffee Shop']\n",
    "    if 'sandwich' in words:\n",
    "        cat = catDict['Sandwich Shop']\n",
    "    predictions.write(l['userID'] + '-' + l['reviewHash'] + \",\" + str(cat) + \"\\n\")\n",
    "\n",
    "predictions.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########Q1\n",
    "import gzip\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "def readGz(f):\n",
    "    for l in gzip.open(f):\n",
    "        yield eval(l)\n",
    "data=list(readGz(\"train.json.gz\"))\n",
    "trainset=data[0:100000]\n",
    "validationset=data[100000:200000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "businesslist = []\n",
    "userlist=[]\n",
    "for l in data:\n",
    "    user,business = l['userID'],l['businessID']\n",
    "    businesslist.append(business)\n",
    "    userlist.append(user)\n",
    "businesslist=list(set(businesslist))  \n",
    "userlist=list(set(userlist))   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "businessIDlist={}\n",
    "userIDlist={}\n",
    "for i in range(len(businesslist)):\n",
    "    businessIDlist[businesslist[i]]=i\n",
    "for j in range(len(userlist)):\n",
    "    userIDlist[userlist[j]]=j\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data1=[]\n",
    "temp=[]\n",
    "for l in data:\n",
    "    dic={}\n",
    "    user,business = l['userID'],l['businessID']\n",
    "    dic['userID']=userIDlist[user]\n",
    "    dic['businessID']=businessIDlist[business]\n",
    "    dic['isvisit']=1\n",
    "    data1.append(dic)\n",
    "    temp.append([userIDlist[user],businessIDlist[business] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###random create validation set\n",
    "import random\n",
    "validset=[]\n",
    "while len(validset)<100000:\n",
    "    dic={}\n",
    "    i=random.randint(0,len(userlist)-1)\n",
    "    j=random.randint(0,len(businesslist)-1)\n",
    "    temp1=[i,j]\n",
    "    if temp1 not in temp:\n",
    "        dic['userID']=i\n",
    "        dic['businessID']=j\n",
    "        dic['isvisit']=0\n",
    "        validset.append(dic)\n",
    "#combine validset\n",
    "valid=data1[100000:200000]+validset        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "traintotal=data1+validset     \n",
    "df=pd.DataFrame(traintotal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "businessCount = defaultdict(int)\n",
    "totalPurchases = 0\n",
    "\n",
    "for l in readGz(\"train.json.gz\"):\n",
    "    user,business = l['userID'],l['businessID']\n",
    "    businessCount[business] += 1\n",
    "    totalPurchases += 1\n",
    "\n",
    "mostPopular = [(businessCount[x], x) for x in businessCount]\n",
    "mostPopular.sort()\n",
    "mostPopular.reverse()\n",
    "\n",
    "return1 = set()\n",
    "count = 0\n",
    "for ic, i in mostPopular:\n",
    "    count += ic\n",
    "    return1.add(i)\n",
    "    if count > totalPurchases/2: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train=df.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train = df.drop('isvisit',axis=1)\n",
    "y_train = df['isvisit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train=X_train.as_matrix()\n",
    "y_train=y_train.as_matrix()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_distances_no_loops(X_train, X):\n",
    "    num_test = X.shape[0]\n",
    "    num_train =X_train.shape[0]\n",
    "    dists = np.zeros((num_test, num_train)) \n",
    "    dists = np.sqrt((X**2).sum(axis=1, keepdims=True) + (X_train**2).sum(axis=1) - 2 * X.dot(X_train.T))\n",
    "    return dists\n",
    "def predict_labels(y_train, dists, k=1):\n",
    "    num_test = dists.shape[0]\n",
    "    y_pred = np.zeros(num_test)\n",
    "    for i in xrange(num_test):     \n",
    "        closest_y = []\n",
    "        closest_y = y_train[np.argsort(dists[i])][:k] \n",
    "        y_pred[i] = np.argmax(np.bincount(closest_y))\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = open(\"predictions_Visit.txt\", 'w')\n",
    "for l in open(\"pairs_Visit.txt\"):\n",
    "    if l.startswith(\"userID\"):\n",
    "    #header\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u,i = l.strip().split('-')\n",
    "#     if i in return1:\n",
    "#         predictions.write(u + '-' + i + \",1\\n\")\n",
    "#     else:\n",
    "#         predictions.write(u + '-' + i + \",0\\n\")\n",
    "    if u in userIDlist and i in businessIDlist:\n",
    "        u_id=userIDlist[u]\n",
    "        i_id=businessIDlist[i]\n",
    "        x_test=np.array((i_id,u_id))\n",
    "        result=neigh.predict([x_test])\n",
    "        result=str(int(result[0]))\n",
    "    elif i in return1:\n",
    "        result=\"1\"\n",
    "    else:\n",
    "        result=\"0\"\n",
    "    predictions.write(u + '-' + i + ',' + result + '\\n')\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=5)\n",
    "neigh.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data2=[]\n",
    "for l in data:\n",
    "    dic={}\n",
    "    user,business,rating = l['userID'],l['businessID'],l[\"rating\"]\n",
    "    dic['userID']=userIDlist[user]\n",
    "    dic['rating']=rating\n",
    "    dic['businessID']=businessIDlist[business]\n",
    "    dic['isvisit']=1\n",
    "    data2.append(dic)\n",
    "    #temp.append([userIDlist[user],businessIDlist[business] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation as cv\n",
    "df2=pd.DataFrame(data2)\n",
    "\n",
    "n_users = df2.userID.unique().shape[0]\n",
    "n_business=df2.businessID.unique().shape[0]\n",
    "train_data, test_data = cv.train_test_split(df2, test_size=0.25)\n",
    "\n",
    "#Create two user-item matrices, one for training and another for testing\n",
    "train_data_matrix = np.zeros((n_users, n_business))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "business1=train_data[\"businessID\"].as_matrix()\n",
    "user1=train_data[\"userID\"].as_matrix()\n",
    "rating1=train_data[\"rating\"].as_matrix()\n",
    "business2=test_data[\"businessID\"].as_matrix()\n",
    "user2=test_data[\"userID\"].as_matrix()\n",
    "rating2=test_data[\"rating\"].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12728, 13578)"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business1[0],user1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for l in range(len(train_data)):\n",
    "    train_data_matrix[user1[l], business1[l]] = rating1[l]\n",
    "test_data_matrix = np.zeros((n_users, n_business))\n",
    "for l in range(len(test_data)):\n",
    "    test_data_matrix[user2[l], business2[l]] = rating2[l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "user_similarity = pairwise_distances(train_data_matrix, metric='cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(ratings, similarity, type='user'):\n",
    "        if type == 'user':\n",
    "            mean_user_rating = ratings.mean(axis=1)\n",
    "            #print mean_user_rating\n",
    "            ratings_diff = (ratings - mean_user_rating[:, np.newaxis]) \n",
    "            pred = mean_user_rating[:, np.newaxis] + similarity.dot(ratings_diff) / np.array([np.abs(similarity).sum(axis=1)]).T   \n",
    "            return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-based CF RMSE: 4.27361586833\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "def rmse(prediction, ground_truth):\n",
    "        prediction = prediction[ground_truth.nonzero()].flatten() \n",
    "        ground_truth = ground_truth[ground_truth.nonzero()].flatten()\n",
    "        return sqrt(mean_squared_error(prediction, ground_truth))\n",
    "                \n",
    "print 'User-based CF RMSE: ' + str(rmse(user_prediction, test_data_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#######\n",
    "userRatings = defaultdict(lambda: defaultdict(int))\n",
    "businessRatings_train = defaultdict(lambda: defaultdict(int))\n",
    "for l in data:\n",
    "    user,business,rating = l['userID'],l['businessID'],l['rating']\n",
    "    userRatings[user][business] = rating\n",
    "    businessRatings_train[business][user] = rating\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def similarity_score(person1,person2,userRatings):\n",
    "    \n",
    "    # Returns ratio Euclidean distance score of person1 and person2 \n",
    "\n",
    "    both_viewed = {}# To get both rated items by person1 and person2\n",
    "\n",
    "    for item in userRatings[person1]:\n",
    "        if item in userRatings[person2]:\n",
    "            both_viewed[item] = 1\n",
    "\n",
    "        # Conditions to check they both have an common rating items\t\n",
    "    if len(both_viewed) == 0:\n",
    "        return 0\n",
    "\n",
    "    # Finding Euclidean distance \n",
    "    sum_of_eclidean_distance = []\n",
    "    for item in userRatings[person1]:\n",
    "        if item in userRatings[person2]:\n",
    "            sum_of_eclidean_distance.append(pow(userRatings[person1][item] - userRatings[person2][item],2))\n",
    "    sum_of_eclidean_distance = sum(sum_of_eclidean_distance)\n",
    "    #print sum_of_eclidean_distance\n",
    "\n",
    "    return 1/(1+sqrt(sum_of_eclidean_distance))*1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B807454692': 1}"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "both_viewed = {}# To get both rated items by person1 and person2\n",
    "for item in userRatings[\"U024954695\"]:\n",
    "    if item in userRatings[\"U058381151\"]:\n",
    "        both_viewed[item] = 1\n",
    "both_viewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pearson_correlation(person1,person2,userRatings):\n",
    "\n",
    "    # To get both rated items\n",
    "    both_rated = {}\n",
    "    for item in userRatings[person1]:\n",
    "        if item in userRatings[person2]:\n",
    "            both_rated[item] = 1\n",
    "\n",
    "    number_of_ratings = len(both_rated)\n",
    "    \n",
    "    # Checking for number of ratings in common\n",
    "    if number_of_ratings == 0:\n",
    "        return 0\n",
    "\n",
    "    # Add up all the preferences of each user\n",
    "    person1_preferences_sum = sum([userRatings[person1][item] for item in both_rated])\n",
    "    person2_preferences_sum = sum([userRatings[person2][item] for item in both_rated])\n",
    "\n",
    "    # Sum up the squares of preferences of each user\n",
    "    person1_square_preferences_sum = sum([pow(userRatings[person1][item],2) for item in both_rated])\n",
    "    person2_square_preferences_sum = sum([pow(userRatings[person2][item],2) for item in both_rated])\n",
    "\n",
    "    # Sum up the product value of both preferences for each item\n",
    "    product_sum_of_both_users = sum([userRatings[person1][item] * userRatings[person2][item] for item in both_rated])\n",
    "\n",
    "    # Calculate the pearson score\n",
    "    numerator_value = product_sum_of_both_users - (person1_preferences_sum*person2_preferences_sum/number_of_ratings)\n",
    "    denominator_value = sqrt((person1_square_preferences_sum - pow(person1_preferences_sum,2)/number_of_ratings) * (person2_square_preferences_sum -pow(person2_preferences_sum,2)/number_of_ratings))\n",
    "    if denominator_value == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        r = numerator_value/denominator_value\n",
    "        return r "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pearson_correlation1(person1,person2,userRatings):\n",
    "\n",
    "    # To get both rated items\n",
    "    both_rated = {}\n",
    "    item1={}\n",
    "    item2={}\n",
    "\n",
    "    for item in userRatings[person1]:\n",
    "        item1[item]=1\n",
    "        if item in userRatings[person2]:\n",
    "            both_rated[item] = 1\n",
    "    for item in userRatings[person2]:\n",
    "        item2[item]=1\n",
    "    number_of_ratings = len(both_rated)\n",
    "    \n",
    "    # Checking for number of ratings in common\n",
    "    if number_of_ratings == 0:\n",
    "        return 0\n",
    "\n",
    "\n",
    "    #average score for user 1 and user2\n",
    "    user1_bar=sum([userRatings[person1][item] for item in item1])/len(item1)\n",
    "    user2_bar=sum([userRatings[person2][item] for item in item2])/len(item2)\n",
    "    \n",
    "    #####\n",
    "    top=sum([(userRatings[person1][item]-user1_bar)*(userRatings[person2][item]-user2_bar) for item in both_rated])\n",
    "    #####\n",
    "    bottom1= sqrt(sum([pow((userRatings[person1][item]-user1_bar),2) for item in both_rated]))\n",
    "    bottom2= sqrt(sum([pow((userRatings[person2][item]-user2_bar),2) for item in both_rated]))\n",
    "    if bottom1*bottom2==0:\n",
    "        return 0\n",
    "    else:\n",
    "        return top/(bottom1*bottom2)\n",
    "    \n",
    "\n",
    "                  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def most_similar_users(person,number_of_users):\n",
    "\t# returns the number_of_users (similar persons) for a given specific person.\n",
    "\tscores = [(pearson_correlation1(person,other_person,userRatings),other_person) for other_person in userRatings if  other_person != person ]\n",
    "\t\n",
    "\t# Sort the similar persons so that highest scores person will appear at the first\n",
    "\tscores.sort()\n",
    "\tscores.reverse()\n",
    "\treturn scores[0:number_of_users]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1.0, 'U998018573'), (1.0, 'U988807085'), (1.0, 'U964717138'), (1.0, 'U955976623'), (1.0, 'U954605752'), (1.0, 'U938695606'), (1.0, 'U935602736'), (1.0, 'U931553259'), (1.0, 'U923196285'), (1.0, 'U908745071'), (1.0, 'U898364001'), (1.0, 'U878954232'), (1.0, 'U851278078'), (1.0, 'U842112328'), (1.0, 'U830025839'), (1.0, 'U806898128'), (1.0, 'U803012061'), (1.0, 'U801666563'), (1.0, 'U801328664'), (1.0, 'U787087972'), (1.0, 'U784218536'), (1.0, 'U772009262'), (1.0, 'U770044015'), (1.0, 'U768126864'), (1.0, 'U746613760'), (1.0, 'U739287075'), (1.0, 'U737881024'), (1.0, 'U735808692'), (1.0, 'U721124121'), (1.0, 'U719203803'), (1.0, 'U705372537'), (1.0, 'U696414886'), (1.0, 'U694597071'), (1.0, 'U688802674'), (1.0, 'U683277484'), (1.0, 'U681872193'), (1.0, 'U680674395'), (1.0, 'U680319518'), (1.0, 'U679140107'), (1.0, 'U674664964'), (1.0, 'U673400876'), (1.0, 'U673182190'), (1.0, 'U671462264'), (1.0, 'U671366769'), (1.0, 'U668448539'), (1.0, 'U667710535'), (1.0, 'U657217729'), (1.0, 'U654353258'), (1.0, 'U652254521'), (1.0, 'U652198809'), (1.0, 'U651579272'), (1.0, 'U650445418'), (1.0, 'U650345650'), (1.0, 'U641201712'), (1.0, 'U606997152'), (1.0, 'U602483334'), (1.0, 'U599777422'), (1.0, 'U586281640'), (1.0, 'U580664558'), (1.0, 'U560799863'), (1.0, 'U552823364'), (1.0, 'U550331524'), (1.0, 'U549524016'), (1.0, 'U547930973'), (1.0, 'U543079316'), (1.0, 'U539589611'), (1.0, 'U530096928'), (1.0, 'U528149013'), (1.0, 'U525822839'), (1.0, 'U523105181'), (1.0, 'U522740448'), (1.0, 'U500451597'), (1.0, 'U490700868'), (1.0, 'U489899521'), (1.0, 'U479358864'), (1.0, 'U477873317'), (1.0, 'U473565167'), (1.0, 'U470149037'), (1.0, 'U467124747'), (1.0, 'U461246252'), (1.0, 'U454195470'), (1.0, 'U453947912'), (1.0, 'U446840485'), (1.0, 'U443486628'), (1.0, 'U436547781'), (1.0, 'U434677213'), (1.0, 'U422489293'), (1.0, 'U417738695'), (1.0, 'U417212784'), (1.0, 'U405273135'), (1.0, 'U388271663'), (1.0, 'U386734669'), (1.0, 'U386614046'), (1.0, 'U383753573'), (1.0, 'U380835945'), (1.0, 'U369811665'), (1.0, 'U366635551'), (1.0, 'U366421359'), (1.0, 'U365888987'), (1.0, 'U356707836')]\n"
     ]
    }
   ],
   "source": [
    "print most_similar_users('U058381151',100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def user_reommendations(person):\n",
    "\n",
    "\t# Gets recommendations for a person by using a weighted average of every other user's rankings\n",
    "\ttotals = {}\n",
    "\tsimSums = {}\n",
    "\trankings_list =[]\n",
    "\tfor other in userRatings:\n",
    "\t\t# don't compare me to myself\n",
    "\t\tif other == person:\n",
    "\t\t\tcontinue\n",
    "\t\tsim = pearson_correlation1(person,other,userRatings)\n",
    "\t\t#print \">>>>>>>\",sim\n",
    "\n",
    "\t\t# ignore scores of zero or lower\n",
    "\t\tif sim <=0: \n",
    "\t\t\tcontinue\n",
    "\t\tfor item in userRatings[other]:\n",
    "\n",
    "\t\t\t# only score movies i haven't seen yet\n",
    "\t\t\tif item not in userRatings[person] or userRatings[person][item] == 0:\n",
    "\n",
    "\t\t\t# Similrity * score\n",
    "\t\t\t\ttotals.setdefault(item,0)\n",
    "\t\t\t\ttotals[item] += userRatings[other][item]* sim\n",
    "\t\t\t\t# sum of similarities\n",
    "\t\t\t\tsimSums.setdefault(item,0)\n",
    "\t\t\t\tsimSums[item]+= sim\n",
    "\n",
    "\t\t# Create the normalized list\n",
    "\n",
    "\trankings = [(total/simSums[item],item) for item,total in totals.items()]\n",
    "\trankings.sort()\n",
    "\trankings.reverse()\n",
    "\t# returns the recommended items\n",
    "\trecommendataions_list = [recommend_item for score,recommend_item in rankings]\n",
    "\treturn recommendataions_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = open(\"predictions_Visit.txt\", 'w')\n",
    "for l in open(\"pairs_Visit.txt\"):\n",
    "    if l.startswith(\"userID\"):\n",
    "    #header\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u,i = l.strip().split('-')\n",
    "    res=0\n",
    "    if u in userIDlist and i in businessIDlist:\n",
    "        business=user_reommendations(u)\n",
    "        if i in business:\n",
    "            res=1\n",
    "            #predictions.write(u + '-' + i + \",1\\n\")\n",
    "#         else:\n",
    "#             for cat in (categorydic[i]):\n",
    "#                 for j in range(len(usercategorydic[u])):\n",
    "#                     if cat in usercategorydic[u][j]:\n",
    "#                          res=1\n",
    "    else:\n",
    "        for cat in (categorydic[i]):\n",
    "            for j in range(len(usercategorydic[u])):\n",
    "                if cat in usercategorydic[u][j]:\n",
    "                     res=1\n",
    "    if res==1:\n",
    "        predictions.write(u + '-' + i + \",1\\n\")\n",
    "    else:\n",
    "        predictions.write(u + '-' + i + \",0\\n\")\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "both_rated = {}\n",
    "for item in userRatings[\"U058381151\"]:\n",
    "    if item in userRatings[\"U024954695\"]:\n",
    "        both_rated[item] = 1\n",
    "\n",
    "number_of_ratings = len(both_rated)\n",
    "number_of_ratings\n",
    "person1_preferences_sum = sum([userRatings[\"U058381151\"][item] for item in both_rated])\n",
    "person2_preferences_sum = sum([userRatings[\"U024954695\"][item] for item in both_rated])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "person1_square_preferences_sum = sum([pow(userRatings[\"U058381151\"][item],2) for item in both_rated])\n",
    "person2_square_preferences_sum = sum([pow(userRatings[\"U024954695\"][item],2) for item in both_rated])\n",
    "product_sum_of_both_users = sum([userRatings[\"U058381151\"][item] * userRatings[\"U024954695\"][item] for item in both_rated])\n",
    "numerator_value = product_sum_of_both_users - (person1_preferences_sum*person2_preferences_sum/number_of_ratings)\n",
    "denominator_value = sqrt((person1_square_preferences_sum - pow(person1_preferences_sum,2)/number_of_ratings) * (person2_square_preferences_sum -pow(person2_preferences_sum,2)/number_of_ratings))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when threshold is 50th percentile\n",
      "accuracy is 0.650585\n"
     ]
    }
   ],
   "source": [
    "##calculate accuracy of baseline on validation set\n",
    "num=0\n",
    "for l in valid:\n",
    "    u=l['businessID']\n",
    "    if u in return1:\n",
    "        y=1\n",
    "    else:\n",
    "        y=0\n",
    "    if y==l['isvisit']:  #count the correct pairs\n",
    "        num+=1\n",
    "acc=num*1.0/len(valid)\n",
    "print \"when threshold is 50th percentile\"\n",
    "print \"accuracy is\",acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when threshold is 67th percentile\n",
      "accuracy is 0.653975\n"
     ]
    }
   ],
   "source": [
    "# change threshold from 50th percentile of popularity to 67th percentile of popularity\n",
    "return1 = set()\n",
    "count = 0\n",
    "for ic, i in mostPopular:\n",
    "    count += ic\n",
    "    return1.add(i)\n",
    "    if count > totalPurchases/1.5: break\n",
    "##calculate accuracy of baseline on validation set\n",
    "num=0\n",
    "for l in valid:\n",
    "    u=l['businessID']\n",
    "    if u in return1:\n",
    "        y=1\n",
    "    else:\n",
    "        y=0\n",
    "    if y==l['isvisit']:  #count the correct pairs\n",
    "        num+=1\n",
    "acc=num*1.0/len(valid)\n",
    "print \"when threshold is 67th percentile\"\n",
    "print \"accuracy is\",acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I change the threshold from 50th percentile of popularity to 67th percentile of popularity. The accuracy slightly increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#####Q3\n",
    "usercategorydic=defaultdict(list)\n",
    "categorydic = defaultdict(list)\n",
    "for l in data:\n",
    "    user,business,categories,rating = l['userID'],l['businessID'],l['categories'],l['rating']\n",
    "    usercategorydic[user].append(categories)\n",
    "    categorydic[business]=(categories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y=[1]*100000+[0]*100000 #create y for valid set\n",
    "y_pred=[0]*len(valid)\n",
    "for i,l in enumerate(valid):\n",
    "    user,business = l['userID'],l['businessID']\n",
    "    #print user,business\n",
    "    if type(usercategorydic[user])!=int and type(categorydic[business])!=int:\n",
    "        for cat in (categorydic[business]):\n",
    "            for i in range(len(usercategorydic[user])):\n",
    "                if cat in usercategorydic[user][i]:\n",
    "                    y_pred[i]=1  #calculate y_pred\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.502855\n"
     ]
    }
   ],
   "source": [
    "#calculate accuracy\n",
    "correct = [(a==b) for (a,b) in zip(y_pred,y)]\n",
    "acc = sum(correct) * 1.0 / len(correct)\n",
    "print \"accuracy is\",acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#####Q4 input the model to pairs_Visit.txt and submit on Kaggle\n",
    "predictions = open(\"predictions_Visit.txt\", 'w')\n",
    "c=0\n",
    "for l in open(\"pairs_Visit.txt\"):\n",
    "    if l.startswith(\"userID\"):\n",
    "    #header\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u,i = l.strip().split('-')\n",
    "    y=0\n",
    "    #if type(usercategorydic[u])!=int and type(categorydic[i])!=int:\n",
    "    for cat in (categorydic[i]):\n",
    "        for j in range(len(usercategorydic[u])):\n",
    "            if cat in usercategorydic[u][j]:\n",
    "                 y=1\n",
    "    if y==1:\n",
    "        predictions.write(u + '-' + i + \",1\\n\")\n",
    "    else:\n",
    "        predictions.write(u + '-' + i + \",0\\n\")\n",
    "    c+=1\n",
    "\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My Kaggle name is Chao Yu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha is 4.18703\n"
     ]
    }
   ],
   "source": [
    "####### Q5\n",
    "import pandas as pd\n",
    "sumofrating=0\n",
    "for l in trainset:\n",
    "    rating=l['rating']\n",
    "    sumofrating+=rating\n",
    "alpha=sumofrating/len(trainset)\n",
    "print \"alpha is\",alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on the validation set is 0.748343744499\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "MSE=0\n",
    "for l in validationset:\n",
    "    rating=l['rating']\n",
    "    MSE+=(alpha-rating)**2\n",
    "MSE=MSE/len(validationset)\n",
    "print \"MSE on the validation set is\",MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "businesslist = []\n",
    "userlist=[]\n",
    "for l in validationset:\n",
    "    user,business = l['userID'],l['businessID']\n",
    "    businesslist.append(business)\n",
    "    userlist.append(user)\n",
    "businesslist=list(set(businesslist))  \n",
    "userlist=list(set(userlist))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#######Q6\n",
    "df=pd.DataFrame(validationset)\n",
    "userRatings_train = defaultdict(lambda: defaultdict(int))\n",
    "businessRatings_train = defaultdict(lambda: defaultdict(int))\n",
    "beta_u = defaultdict(float)\n",
    "beta_i = defaultdict(float)\n",
    "gamma_u= defaultdict(float)\n",
    "gamma_i= defaultdict(float)\n",
    "\n",
    "for l in data:\n",
    "    user,business,rating = l['userID'],l['businessID'],l['rating']\n",
    "    userRatings_train[user][business] = rating\n",
    "    businessRatings_train[business][user] = rating\n",
    "    #random initialization\n",
    "    beta_u[user] = random.randint(1,100)/1000.0  \n",
    "    beta_i[business] = random.randint(1,100)/1000.0\n",
    "    gamma_u[user] = random.randint(1,100)/1000.0  \n",
    "    gamma_i[business] = random.randint(1,100)/1000.0  \n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lamda = 1\n",
    "iteration = 0\n",
    "while iteration <= 100:\n",
    "    # update alpha\n",
    "    \n",
    "    alpha=sum(df[\"rating\"])\n",
    "    for user in userRatings_train:\n",
    "        for business in userRatings_train[user]:\n",
    "            alpha -= (beta_u[user] + beta_i[business])\n",
    "    alpha /= len(trainset)\n",
    "    # update beta_u\n",
    "    for user in userRatings_train:\n",
    "        beta_u[user] = 0\n",
    "        for business in userRatings_train[user]:\n",
    "            beta_u[user] += userRatings_train[user][business] \\\n",
    "                    - (alpha + beta_i[business])\n",
    "        beta_u[user] /= (lamda + len(userRatings_train[user])) \n",
    "    # update beta_i\n",
    "    for business in businessRatings_train:\n",
    "        beta_i[business] = 0\n",
    "        for user in businessRatings_train[business]:\n",
    "            beta_i[business] += businessRatings_train[business][user] \\\n",
    "                    - (alpha + beta_u[user])\n",
    "        beta_i[business] /= (lamda + len(businessRatings_train[business]))\n",
    "    iteration += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on validation set 2.00767269453e+55\n"
     ]
    }
   ],
   "source": [
    "### calculate MSE on validation set\n",
    "userRatings_valid = defaultdict(lambda: defaultdict(int))\n",
    "businessRatings_valid = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for l in validationset:\n",
    "    user,business,rating = l['userID'],l['businessID'],l['rating']\n",
    "    userRatings_valid[user][business] = rating\n",
    "    businessRatings_valid[business][user] = rating\n",
    "MSE = 0\n",
    "for user in userRatings_valid:\n",
    "    for business in userRatings_valid[user]:\n",
    "        x=alpha\n",
    "        if user in beta_u:\n",
    "            x+=beta_u[user]\n",
    "        if business in beta_i:\n",
    "            x+=beta_i[business]\n",
    "        MSE+=((x-userRatings_valid[user][business])**2)\n",
    "\n",
    "MSE /= len(validationset)\n",
    "print \"MSE on validation set\",MSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user id with maximum beta is U357799541\n",
      "maximum beta is 1.1793783493\n",
      "user id with minimum beta is U417838537\n",
      "minimum beta is -2.80365895513\n",
      "business id with maximum beta is B093985406\n",
      "maximum beta is 1.18311575064\n",
      "business id with minimum beta is B241777680\n",
      "minimum beta is -2.21741811964\n"
     ]
    }
   ],
   "source": [
    "####Q7\n",
    "import operator\n",
    "sorted_beta_u=sorted(beta_u.items(), key=operator.itemgetter(1))\n",
    "sorted_beta_i=sorted(beta_i.items(), key=operator.itemgetter(1))\n",
    "print \"user id with maximum beta is\",sorted_beta_u[-1][0]\n",
    "print \"maximum beta is\",sorted_beta_u[-1][1]\n",
    "print \"user id with minimum beta is\",sorted_beta_u[0][0]\n",
    "print \"minimum beta is\",sorted_beta_u[0][1]\n",
    "print \"business id with maximum beta is\",sorted_beta_i[-1][0]\n",
    "print \"maximum beta is\",sorted_beta_i[-1][1]\n",
    "print \"business id with minimum beta is\",sorted_beta_i[0][0]\n",
    "print \"minimum beta is\",sorted_beta_i[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lamda is 8\n",
      "MSE for training set is 2.16645929841e+100\n",
      "MSE for validation set is 1.08365624909e+100\n",
      "lamda is 9\n",
      "MSE for training set is 3.52313312698e+141\n",
      "MSE for validation set is 1.76206437062e+141\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-410-b51defeef629>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mbeta_u\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbusiness\u001b[0m \u001b[0;32min\u001b[0m \u001b[0muserRatings_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0mbeta_u\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0muserRatings_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbusiness\u001b[0m\u001b[0;34m]\u001b[0m                         \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbeta_i\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbusiness\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0mbeta_u\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlamda\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muserRatings_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# update beta_i\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lamdaset=[0.01,0.1,1,10,100,1000,10000]\n",
    "for lamda in lamdaset:\n",
    "    iteration = 0\n",
    "    while iteration <= 100:\n",
    "    # update alpha\n",
    "        alpha=sum(df[\"rating\"])\n",
    "        for user in userRatings_train:\n",
    "            for business in userRatings_train[user]:\n",
    "                alpha -= (beta_u[user] + beta_i[business])\n",
    "        alpha /= len(trainset)\n",
    "        # update beta_u\n",
    "        for user in userRatings_train:\n",
    "            beta_u[user] = 0\n",
    "            for business in userRatings_train[user]:\n",
    "                beta_u[user] += userRatings_train[user][business] \\\n",
    "                        - (alpha + beta_i[business])\n",
    "            beta_u[user] /= (lamda + len(userRatings_train[user])) \n",
    "        # update beta_i\n",
    "        for business in businessRatings_train:\n",
    "            beta_i[business] = 0\n",
    "            for user in businessRatings_train[business]:\n",
    "                beta_i[business] += businessRatings_train[business][user] \\\n",
    "                        - (alpha + beta_u[user])\n",
    "            beta_i[business] /= (lamda + len(businessRatings_train[business]))\n",
    "        # MSE\n",
    "        MSE = 0\n",
    "        for user in userRatings_train:\n",
    "            for business in userRatings_train[user]:\n",
    "                MSE += (alpha + beta_u[user] + beta_i[business] \n",
    "                        - userRatings_train[user][business]) **2\n",
    "        MSE /= len(trainset)\n",
    "        if iteration==100:\n",
    "            print \"lamda is\", lamda\n",
    "            print \"MSE for training set is\", MSE\n",
    "        iteration+=1\n",
    "    ### calculate MSE on validation set\n",
    "    userRatings_valid = defaultdict(lambda: defaultdict(int))\n",
    "    businessRatings_valid = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "    for l in validationset:\n",
    "        user,business,rating = l['userID'],l['businessID'],l['rating']\n",
    "        userRatings_valid[user][business] = rating\n",
    "        businessRatings_valid[business][user] = rating\n",
    "    MSE = 0\n",
    "    for user in userRatings_valid:\n",
    "        for business in userRatings_valid[user]:\n",
    "            x=alpha\n",
    "            if user in beta_u:\n",
    "                x+=beta_u[user]\n",
    "            if business in beta_i:\n",
    "                x+=beta_i[business]\n",
    "            MSE+=(x-userRatings_valid[user][business])**2\n",
    "\n",
    "    MSE /= len(validationset)\n",
    "    print \"MSE for validation set is\",MSE\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see when lamda is 10, the MSE for validation set is lowest, which is 0.621537959215."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lamda = 10\n",
    "iteration = 0\n",
    "while iteration <= 100:\n",
    "    # update alpha\n",
    "    \n",
    "    alpha=sum(df[\"rating\"])\n",
    "    for user in userRatings_train:\n",
    "        for business in userRatings_train[user]:\n",
    "            alpha -= (beta_u[user] + beta_i[business])\n",
    "    alpha /= len(trainset)\n",
    "    # update beta_u\n",
    "    for user in userRatings_train:\n",
    "        beta_u[user] = 0\n",
    "        for business in userRatings_train[user]:\n",
    "            beta_u[user] += userRatings_train[user][business] \\\n",
    "                    - (alpha + beta_i[business])\n",
    "        beta_u[user] /= (lamda + len(userRatings_train[user])) \n",
    "    # update beta_i\n",
    "    for business in businessRatings_train:\n",
    "        beta_i[business] = 0\n",
    "        for user in businessRatings_train[business]:\n",
    "            beta_i[business] += businessRatings_train[business][user] \\\n",
    "                    - (alpha + beta_u[user])\n",
    "        beta_i[business] /= (lamda + len(businessRatings_train[business]))\n",
    "    # MSE\n",
    "    MSE = 0\n",
    "    for user in userRatings_train:\n",
    "        for business in userRatings_train[user]:\n",
    "            MSE += (alpha + beta_u[user] + beta_i[business] \n",
    "                    - userRatings_train[user][business]) **2\n",
    "    MSE /= len(trainset)\n",
    "    iteration += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = open(\"predictions_Rating.txt\", 'w')\n",
    "for l in open(\"pairs_Rating.txt\"):\n",
    "    if l.startswith(\"userID\"):\n",
    "        #header\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u,i = l.strip().split('-')\n",
    "    x=alpha\n",
    "    if u in beta_u:\n",
    "        x += beta_u[u]\n",
    "    if i in beta_i:\n",
    "        x += beta_i[i] \n",
    "        \n",
    "    predictions.write(u + '-' + i + ',' + str(x) + '\\n')\n",
    "    \n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "userRatings = defaultdict(lambda: defaultdict(int))\n",
    "businessRatings = defaultdict(lambda: defaultdict(int))\n",
    "beta_u = defaultdict(float)\n",
    "beta_i = defaultdict(float)\n",
    "\n",
    "\n",
    "for l in data:\n",
    "    user,business,rating = l['userID'],l['businessID'],l['rating']\n",
    "    userRatings[user][business] = rating\n",
    "    businessRatings[business][user] = rating\n",
    "    #random initialization\n",
    "    beta_u[user] = random.randint(1,100)/1000.0  \n",
    "    beta_i[business] = random.randint(1,100)/1000.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###### Use all data to make prediction\n",
    "df=pd.DataFrame(data)\n",
    "lamda = 10\n",
    "iteration = 0\n",
    "while iteration <= 100:\n",
    "    # update alpha\n",
    "    \n",
    "    alpha=sum(df[\"rating\"])\n",
    "    for user in userRatings:\n",
    "        for business in userRatings[user]:\n",
    "            alpha -= (beta_u[user] + beta_i[business])\n",
    "    alpha /= len(data)\n",
    "    # update beta_u\n",
    "    for user in userRatings:\n",
    "        beta_u[user] = 0\n",
    "        for business in userRatings[user]:\n",
    "            beta_u[user] += userRatings[user][business] \\\n",
    "                    - (alpha + beta_i[business])\n",
    "        beta_u[user] /= (lamda + len(userRatings[user])) \n",
    "    # update beta_i\n",
    "    for business in businessRatings:\n",
    "        beta_i[business] = 0\n",
    "        for user in businessRatings[business]:\n",
    "            beta_i[business] += businessRatings[business][user] \\\n",
    "                    - (alpha + beta_u[user])\n",
    "        beta_i[business] /= (lamda + len(businessRatings[business]))\n",
    "    iteration += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = open(\"predictions_Rating.txt\", 'w')\n",
    "for l in open(\"pairs_Rating.txt\"):\n",
    "    if l.startswith(\"userID\"):\n",
    "        #header\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u,i = l.strip().split('-')\n",
    "    x=alpha\n",
    "    if u in beta_u:\n",
    "        x += beta_u[u]\n",
    "    if i in beta_i:\n",
    "        x += beta_i[i] \n",
    "        \n",
    "    predictions.write(u + '-' + i + ',' + str(x) + '\\n')\n",
    "    \n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
